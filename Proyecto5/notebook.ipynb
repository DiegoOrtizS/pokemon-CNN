{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4ae14676daf9464d8ce41c00f7067385",
    "deepnote_cell_height": 82,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "dca0b91c68df4f6ba8f4ae66fd2d4638",
    "deepnote_cell_height": 495,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1656113514131,
    "source_hash": "c29ad971",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "from urllib.request import Request, urlopen, urlretrieve\n",
    "from typing import List\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "from typing_extensions import Required\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, precision_score\n",
    "from svglib.svglib import svg2rlg\n",
    "from reportlab.graphics import renderPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c371cb3d7f6048e1a5dfe620c157b225",
    "deepnote_cell_height": 134,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Extracción de datos con web scrapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "81c208ada4864ecc85c464e87885a67d",
    "deepnote_cell_height": 99,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1656112784191,
    "source_hash": "f913a6e2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# son 905, pero los últimos no tienen data\n",
    "max_pokemon: int = 898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [\"grass\", \"fire\", \"water\", \"electric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "1faf299810584c6a8b5973511feceff5",
    "deepnote_cell_height": 117,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1656112784205,
    "source_hash": "5c166d96",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir1: str = \"official-artwork\"\n",
    "if os.path.exists(dir1) == False:\n",
    "    os.mkdir(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir2: str = \"all\"\n",
    "if os.path.exists(dir2) == False:\n",
    "    os.mkdir(dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "409ad1cd53bd41938e258722df74999e",
    "deepnote_cell_height": 333,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 38558,
    "execution_start": 1656112784214,
    "source_hash": "3b6ed317",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "SOLO PARA DESCARGAR DATOS\n",
    "\"\"\"\n",
    "# for pokemon_id in range(max_pokemon):\n",
    "#     req: Request = Request(\"https://pokeapi.co/api/v2/pokemon/\"+str(pokemon_id+1), \n",
    "#                     headers={'User-Agent': 'Mozilla/5.0'})\n",
    "#     webpage: bytes = urlopen(req).read()\n",
    "#     json_obj: dict = json.loads(webpage)\n",
    "#     img_url: str = json_obj[\"sprites\"][\"other\"][\"official-artwork\"][\"front_default\"]\n",
    "    \n",
    "#     name: str = json_obj[\"species\"][\"name\"]\n",
    "#     type: str = json_obj[\"types\"][0][\"type\"][\"name\"]\n",
    "\n",
    "#     if os.path.exists(dir1+\"/\"+type) == False:\n",
    "#         os.mkdir(dir1+\"/\"+type)\n",
    "    \n",
    "#     img: str = img_url.split(\"/\")[-1]\n",
    "#     urlretrieve(img_url, dir1+\"/\"+type+\"/\"+name+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_category: list = [\"official-artwork\", \"home\", \"dream_world\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type in types:\n",
    "    if os.path.exists(dir2+\"/\"+type) == False:\n",
    "        os.mkdir(dir2+\"/\"+type)\n",
    "    # if os.path.exists(\"svg/\"+type) == False:\n",
    "    #     os.mkdir(\"svg/\"+type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "SOLO PARA DESCARGAR DATOS\n",
    "\"\"\"\n",
    "# for pokemon_id in range(max_pokemon):\n",
    "#     print(pokemon_id+1)\n",
    "#     req: Request = Request(\"https://pokeapi.co/api/v2/pokemon/\"+str(pokemon_id+1), \n",
    "#                     headers={'User-Agent': 'Mozilla/5.0'})\n",
    "#     webpage: bytes = urlopen(req).read()\n",
    "#     json_obj: dict = json.loads(webpage)\n",
    "#     type: str = json_obj[\"types\"][0][\"type\"][\"name\"]\n",
    "#     if type not in types:\n",
    "#         continue\n",
    "#     name: str = json_obj[\"species\"][\"name\"]\n",
    "\n",
    "#     for img_category in imgs_category:\n",
    "#         img_url: str = json_obj[\"sprites\"][\"other\"][img_category][\"front_default\"]\n",
    "#         if img_url == None:\n",
    "#             continue\n",
    "#         save_route: str = \"/\"+type+\"/\"+name+\"_\"+img_category+\".\"\n",
    "#         format: str = img_url[-3:]\n",
    "#         if format == \"svg\":\n",
    "#             urlretrieve(img_url, \"svg\"+save_route+format)\n",
    "#             drawing = svg2rlg(\"svg\"+save_route+format)\n",
    "#             renderPM.drawToFile(drawing, dir2+save_route+\"png\", fmt=\"PNG\")\n",
    "#         else:\n",
    "#             urlretrieve(img_url, dir2+save_route+format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grass 86\n",
      "fire 58\n",
      "water 123\n",
      "electric 49\n",
      "['grass', 'fire', 'water', 'electric']\n"
     ]
    }
   ],
   "source": [
    "# Distribución de los datos\n",
    "for type in types:\n",
    "    print(type, len(os.listdir(dir1+\"/\"+type)))\n",
    "# types.remove(\"flying\")\n",
    "print(types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grass 233\n",
      "fire 155\n",
      "water 346\n",
      "electric 131\n",
      "865\n"
     ]
    }
   ],
   "source": [
    "# Distribución de los datos\n",
    "sum: int = 0\n",
    "for type in types:\n",
    "    freq: int = len(os.listdir(dir2+\"/\"+type))\n",
    "    sum += freq\n",
    "    print(type, freq)\n",
    "# types.remove(\"flying\")\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "896da40b711a4f8888ab27620132e8d7",
    "deepnote_cell_height": 82,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5c307bb8ebb544d2bc70ddd752aba283",
    "deepnote_cell_height": 70,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c159bd33463a49e687f206ca20f7e0ae",
    "deepnote_cell_height": 538.203125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 728,
    "execution_start": 1656112822774,
    "owner_user_id": "32a19c20-c19c-4be0-b488-d37ed4f5b741",
    "source_hash": "7195c826",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.alexnet(pretrained=True)\n",
    "for e in model.parameters():\n",
    "   e.requires_grad = False\n",
    "model.classifier[4] = nn.Linear(4096, 1024)\n",
    "model.classifier[6] = nn.Linear(1024, len(types))\n",
    "# model.classifier[6] = nn.Linear(4096, len(types))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x: List[str] = []\n",
    "y: List[str] = []\n",
    "for type in types:\n",
    "    pokemon_imgs: List[str] = os.listdir(dir2+\"/\"+type)\n",
    "    for pokemon_img in pokemon_imgs:\n",
    "        x.append(dir2+\"/\"+type+\"/\"+pokemon_img)\n",
    "        y.append(type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "      def __init__(self, list_IDs, labels):\n",
    "            self.labels = labels\n",
    "            self.list_IDs = list_IDs\n",
    "\n",
    "      def __len__(self):\n",
    "            return len(self.list_IDs)\n",
    "\n",
    "      def __getitem__(self, index):\n",
    "            # Select sample\n",
    "            ID = self.list_IDs[index]\n",
    "\n",
    "            # Load data and get label\n",
    "            input_image = Image.open(ID)\n",
    "            input_image = input_image.convert('RGB')\n",
    "            preprocess = transforms.Compose([\n",
    "                  transforms.Resize(256),\n",
    "                  transforms.CenterCrop(224),\n",
    "                  transforms.RandomHorizontalFlip(),\n",
    "                  transforms.ToTensor()\n",
    "            ])\n",
    "            X = preprocess(input_image)\n",
    "            y = self.labels[index]\n",
    "            return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "tensor_y = le.fit_transform(y)\n",
    "tensor_y = torch.as_tensor(tensor_y)\n",
    "dataset = MyDataset(x, tensor_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val, data_test = random_split(dataset=dataset, lengths=[605, 87, 173])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=data_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=data_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=data_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "cell_id": "36701edd37294ababa555381dad795f7",
    "deepnote_cell_height": 99,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1656113535112,
    "source_hash": "fc1d418",
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-4, weight_decay=0.005, momentum=0.9)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "total_step = len(train_loader)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, num_epochs) -> List[float]:\n",
    "  # train the model\n",
    "  total_step: int = len(train_loader)\n",
    "  print(total_step)\n",
    "\n",
    "  list_train_loss: List[float] = []\n",
    "  list_val_loss: List[float] = []\n",
    "\n",
    "  beg = time.time()\n",
    "  for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      # forward \n",
    "      output = model(images)\n",
    "      loss   = loss_fn(output, labels)\n",
    "      # change the params\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      # del images, labels, output\n",
    "    \n",
    "    train_loss: float = loss.item()\n",
    "    list_train_loss.append(train_loss)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images, labels in val_loader:\n",
    "          correct = 0\n",
    "          total = 0\n",
    "          for images, labels in val_loader:\n",
    "              images = images.to(device)\n",
    "              labels = labels.to(device)\n",
    "              outputs = model(images)\n",
    "              loss = loss_fn(outputs, labels)\n",
    "              _, predicted = torch.max(outputs.data, 1)\n",
    "              total += labels.size(0)\n",
    "              correct += (predicted == labels).sum().item()\n",
    "              del images, labels, outputs\n",
    "\n",
    "        val_loss: float = loss.detach().cpu()\n",
    "        list_val_loss.append(val_loss)\n",
    "        print ('Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss {:.4f},  Accuracy: {:.4f}'\n",
    "              .format(epoch+1, num_epochs, train_loss, val_loss, 100*correct/total))\n",
    "  end = time.time()\n",
    "  print('Finished training trainset in {} seconds'.format(round(end-beg, 2)))\n",
    "\n",
    "  return list_train_loss, list_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, save_name: str = \"\"):\n",
    "    with torch.no_grad():\n",
    "        all_predicted: list = []\n",
    "        all_labels: list = []\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_predicted.extend((predicted).tolist())\n",
    "            all_labels.extend((labels).tolist())\n",
    "        val = (np.unique(le.inverse_transform(all_predicted)))\n",
    "        matrix = confusion_matrix(all_labels, all_predicted)\n",
    "        df = pd.DataFrame(matrix, index=val, columns=val)\n",
    "        sns.heatmap(df, annot=True, cbar=None, cmap=\"Greens\")\n",
    "        plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Real\")\n",
    "        if save_name == \"\":\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(PATH_RES+save_name)\n",
    "        print('Test of the model on the {} test images'.format(len(data_test)))\n",
    "        print('Acurracy: {:.2f} %'.format(100*accuracy_score(all_labels, all_predicted)))\n",
    "        print('F1-score: {:.2f} %'.format(100*f1_score(all_labels, all_predicted, average='macro')))\n",
    "        print('Recall: {:.2f} %'.format(100*recall_score(all_labels, all_predicted, average='macro')))\n",
    "        print('Precision: {:.2f} %'.format(100*precision_score(all_labels, all_predicted, average='macro')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test before train\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch [1/100], Train Loss: 1.1672, Validation Loss 1.1509,  Accuracy: 52.8736\n",
      "Epoch [2/100], Train Loss: 0.8134, Validation Loss 0.9039,  Accuracy: 60.9195\n",
      "Epoch [3/100], Train Loss: 0.8545, Validation Loss 0.7771,  Accuracy: 70.1149\n",
      "Epoch [4/100], Train Loss: 0.6088, Validation Loss 0.7959,  Accuracy: 66.6667\n",
      "Epoch [5/100], Train Loss: 0.6903, Validation Loss 0.6928,  Accuracy: 68.9655\n",
      "Epoch [6/100], Train Loss: 0.5418, Validation Loss 0.6854,  Accuracy: 72.4138\n",
      "Epoch [7/100], Train Loss: 0.5656, Validation Loss 0.6352,  Accuracy: 72.4138\n",
      "Epoch [8/100], Train Loss: 0.7385, Validation Loss 0.6013,  Accuracy: 72.4138\n",
      "Epoch [9/100], Train Loss: 0.5759, Validation Loss 0.6075,  Accuracy: 71.2644\n",
      "Epoch [10/100], Train Loss: 0.4402, Validation Loss 0.5731,  Accuracy: 73.5632\n",
      "Epoch [11/100], Train Loss: 0.4763, Validation Loss 0.6028,  Accuracy: 73.5632\n",
      "Epoch [12/100], Train Loss: 0.5027, Validation Loss 0.5582,  Accuracy: 72.4138\n",
      "Epoch [13/100], Train Loss: 0.5463, Validation Loss 0.5074,  Accuracy: 74.7126\n",
      "Epoch [14/100], Train Loss: 0.4889, Validation Loss 0.5407,  Accuracy: 74.7126\n",
      "Epoch [15/100], Train Loss: 0.5829, Validation Loss 0.5535,  Accuracy: 75.8621\n",
      "Epoch [16/100], Train Loss: 0.4261, Validation Loss 0.5256,  Accuracy: 73.5632\n",
      "Epoch [17/100], Train Loss: 0.4673, Validation Loss 0.5031,  Accuracy: 74.7126\n",
      "Epoch [18/100], Train Loss: 0.5092, Validation Loss 0.5146,  Accuracy: 73.5632\n",
      "Epoch [19/100], Train Loss: 0.4783, Validation Loss 0.4806,  Accuracy: 73.5632\n",
      "Epoch [20/100], Train Loss: 0.4553, Validation Loss 0.4779,  Accuracy: 77.0115\n",
      "Epoch [21/100], Train Loss: 0.3877, Validation Loss 0.4596,  Accuracy: 74.7126\n",
      "Epoch [22/100], Train Loss: 0.4633, Validation Loss 0.4577,  Accuracy: 75.8621\n",
      "Epoch [23/100], Train Loss: 0.2197, Validation Loss 0.5252,  Accuracy: 74.7126\n",
      "Epoch [24/100], Train Loss: 0.4271, Validation Loss 0.4205,  Accuracy: 75.8621\n",
      "Epoch [25/100], Train Loss: 0.2749, Validation Loss 0.4862,  Accuracy: 75.8621\n",
      "Epoch [26/100], Train Loss: 0.3865, Validation Loss 0.4438,  Accuracy: 75.8621\n",
      "Epoch [27/100], Train Loss: 0.3807, Validation Loss 0.4812,  Accuracy: 73.5632\n",
      "Epoch [28/100], Train Loss: 0.3727, Validation Loss 0.4389,  Accuracy: 77.0115\n",
      "Epoch [29/100], Train Loss: 0.3309, Validation Loss 0.4524,  Accuracy: 77.0115\n",
      "Epoch [30/100], Train Loss: 0.4451, Validation Loss 0.4874,  Accuracy: 75.8621\n",
      "Epoch [31/100], Train Loss: 0.4424, Validation Loss 0.4482,  Accuracy: 77.0115\n",
      "Epoch [32/100], Train Loss: 0.3080, Validation Loss 0.4800,  Accuracy: 74.7126\n",
      "Epoch [33/100], Train Loss: 0.2923, Validation Loss 0.4800,  Accuracy: 77.0115\n",
      "Epoch [34/100], Train Loss: 0.2734, Validation Loss 0.4559,  Accuracy: 78.1609\n",
      "Epoch [35/100], Train Loss: 0.1884, Validation Loss 0.4297,  Accuracy: 77.0115\n",
      "Epoch [36/100], Train Loss: 0.3340, Validation Loss 0.4517,  Accuracy: 74.7126\n",
      "Epoch [37/100], Train Loss: 0.2821, Validation Loss 0.4428,  Accuracy: 78.1609\n",
      "Epoch [38/100], Train Loss: 0.2113, Validation Loss 0.4295,  Accuracy: 79.3103\n",
      "Epoch [39/100], Train Loss: 0.2009, Validation Loss 0.4652,  Accuracy: 78.1609\n",
      "Epoch [40/100], Train Loss: 0.2181, Validation Loss 0.4205,  Accuracy: 78.1609\n",
      "Epoch [41/100], Train Loss: 0.3056, Validation Loss 0.4593,  Accuracy: 79.3103\n",
      "Epoch [42/100], Train Loss: 0.1678, Validation Loss 0.4115,  Accuracy: 78.1609\n",
      "Epoch [43/100], Train Loss: 0.3698, Validation Loss 0.4274,  Accuracy: 79.3103\n",
      "Epoch [44/100], Train Loss: 0.2279, Validation Loss 0.4608,  Accuracy: 77.0115\n",
      "Epoch [45/100], Train Loss: 0.4274, Validation Loss 0.4261,  Accuracy: 74.7126\n",
      "Epoch [46/100], Train Loss: 0.2892, Validation Loss 0.4329,  Accuracy: 79.3103\n",
      "Epoch [47/100], Train Loss: 0.2105, Validation Loss 0.4509,  Accuracy: 77.0115\n",
      "Epoch [48/100], Train Loss: 0.2575, Validation Loss 0.4007,  Accuracy: 79.3103\n",
      "Epoch [49/100], Train Loss: 0.2422, Validation Loss 0.4194,  Accuracy: 77.0115\n",
      "Epoch [50/100], Train Loss: 0.2348, Validation Loss 0.3799,  Accuracy: 79.3103\n",
      "Epoch [51/100], Train Loss: 0.2662, Validation Loss 0.4259,  Accuracy: 78.1609\n",
      "Epoch [52/100], Train Loss: 0.2379, Validation Loss 0.4162,  Accuracy: 77.0115\n",
      "Epoch [53/100], Train Loss: 0.2144, Validation Loss 0.4312,  Accuracy: 77.0115\n",
      "Epoch [54/100], Train Loss: 0.2464, Validation Loss 0.4751,  Accuracy: 77.0115\n",
      "Epoch [55/100], Train Loss: 0.3199, Validation Loss 0.4124,  Accuracy: 78.1609\n",
      "Epoch [56/100], Train Loss: 0.2957, Validation Loss 0.4448,  Accuracy: 77.0115\n",
      "Epoch [57/100], Train Loss: 0.1445, Validation Loss 0.4491,  Accuracy: 79.3103\n",
      "Epoch [58/100], Train Loss: 0.2199, Validation Loss 0.4173,  Accuracy: 79.3103\n",
      "Epoch [59/100], Train Loss: 0.1530, Validation Loss 0.4067,  Accuracy: 78.1609\n",
      "Epoch [60/100], Train Loss: 0.2170, Validation Loss 0.4376,  Accuracy: 78.1609\n",
      "Epoch [61/100], Train Loss: 0.2770, Validation Loss 0.4302,  Accuracy: 78.1609\n",
      "Epoch [62/100], Train Loss: 0.2284, Validation Loss 0.4472,  Accuracy: 79.3103\n",
      "Epoch [63/100], Train Loss: 0.1410, Validation Loss 0.4248,  Accuracy: 79.3103\n",
      "Epoch [64/100], Train Loss: 0.1864, Validation Loss 0.3902,  Accuracy: 79.3103\n",
      "Epoch [65/100], Train Loss: 0.1808, Validation Loss 0.4401,  Accuracy: 75.8621\n",
      "Epoch [66/100], Train Loss: 0.1436, Validation Loss 0.4308,  Accuracy: 78.1609\n",
      "Epoch [67/100], Train Loss: 0.2097, Validation Loss 0.4315,  Accuracy: 79.3103\n",
      "Epoch [68/100], Train Loss: 0.2723, Validation Loss 0.4128,  Accuracy: 79.3103\n",
      "Epoch [69/100], Train Loss: 0.2091, Validation Loss 0.4227,  Accuracy: 79.3103\n",
      "Epoch [70/100], Train Loss: 0.1717, Validation Loss 0.4425,  Accuracy: 79.3103\n",
      "Epoch [71/100], Train Loss: 0.1527, Validation Loss 0.4693,  Accuracy: 78.1609\n",
      "Epoch [72/100], Train Loss: 0.1890, Validation Loss 0.4401,  Accuracy: 77.0115\n",
      "Epoch [73/100], Train Loss: 0.2153, Validation Loss 0.4397,  Accuracy: 79.3103\n",
      "Epoch [74/100], Train Loss: 0.1296, Validation Loss 0.4464,  Accuracy: 78.1609\n",
      "Epoch [75/100], Train Loss: 0.1962, Validation Loss 0.4229,  Accuracy: 78.1609\n",
      "Epoch [76/100], Train Loss: 0.1863, Validation Loss 0.4264,  Accuracy: 79.3103\n",
      "Epoch [77/100], Train Loss: 0.2684, Validation Loss 0.3856,  Accuracy: 79.3103\n",
      "Epoch [78/100], Train Loss: 0.0954, Validation Loss 0.3865,  Accuracy: 81.6092\n",
      "Epoch [79/100], Train Loss: 0.1414, Validation Loss 0.4700,  Accuracy: 78.1609\n",
      "Epoch [80/100], Train Loss: 0.2802, Validation Loss 0.3864,  Accuracy: 79.3103\n",
      "Epoch [81/100], Train Loss: 0.1971, Validation Loss 0.4485,  Accuracy: 79.3103\n",
      "Epoch [82/100], Train Loss: 0.0968, Validation Loss 0.4245,  Accuracy: 80.4598\n",
      "Epoch [83/100], Train Loss: 0.1730, Validation Loss 0.4032,  Accuracy: 80.4598\n",
      "Epoch [84/100], Train Loss: 0.1308, Validation Loss 0.4042,  Accuracy: 81.6092\n",
      "Epoch [85/100], Train Loss: 0.1743, Validation Loss 0.4148,  Accuracy: 79.3103\n",
      "Epoch [86/100], Train Loss: 0.1197, Validation Loss 0.4456,  Accuracy: 79.3103\n",
      "Epoch [87/100], Train Loss: 0.1798, Validation Loss 0.4612,  Accuracy: 79.3103\n",
      "Epoch [88/100], Train Loss: 0.2567, Validation Loss 0.4281,  Accuracy: 79.3103\n",
      "Epoch [89/100], Train Loss: 0.1677, Validation Loss 0.4295,  Accuracy: 80.4598\n",
      "Epoch [90/100], Train Loss: 0.2002, Validation Loss 0.4277,  Accuracy: 79.3103\n",
      "Epoch [91/100], Train Loss: 0.1542, Validation Loss 0.4647,  Accuracy: 79.3103\n",
      "Epoch [92/100], Train Loss: 0.1778, Validation Loss 0.4118,  Accuracy: 80.4598\n",
      "Epoch [93/100], Train Loss: 0.1271, Validation Loss 0.4055,  Accuracy: 81.6092\n",
      "Epoch [94/100], Train Loss: 0.1802, Validation Loss 0.3970,  Accuracy: 80.4598\n",
      "Epoch [95/100], Train Loss: 0.1215, Validation Loss 0.4300,  Accuracy: 80.4598\n",
      "Epoch [96/100], Train Loss: 0.2305, Validation Loss 0.4413,  Accuracy: 80.4598\n",
      "Epoch [97/100], Train Loss: 0.1069, Validation Loss 0.4028,  Accuracy: 80.4598\n",
      "Epoch [98/100], Train Loss: 0.1390, Validation Loss 0.4370,  Accuracy: 79.3103\n",
      "Epoch [99/100], Train Loss: 0.1185, Validation Loss 0.4804,  Accuracy: 80.4598\n",
      "Epoch [100/100], Train Loss: 0.1424, Validation Loss 0.4739,  Accuracy: 77.0115\n",
      "Finished training trainset in 458.29 seconds\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(model, optimizer, loss_fn, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_RES: str = \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test after train\n",
    "torch.manual_seed(1)\n",
    "test(model, \"alexnet confusion matrix SGD epochs=100 lr=3e-4 weight_decay=0.005 momentum=0.9.png\")\n",
    "# test(model, \"alexnet confusion matrix Adam epochs=100 lr=0.01.png\")\n",
    "# test(model, \"alexnet confusion (sin modificar classifier alexnet) matrix SGD epochs=100 lr=3e-4 weight_decay=0.005 momentum=0.9.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss, label=\"train loss\")\n",
    "plt.plot(val_loss, label=\"val loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"num epochs\")\n",
    "plt.title(\"Loss vs num epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(PATH_RES+\"alexnet loss SGD epochs=100 lr=3e-4 weight_decay=0.005 momentum=0.9.png\")\n",
    "# plt.savefig(PATH_RES+\"alexnet loss Adam epochs=100 lr=0.01.png\")\n",
    "# plt.savefig(PATH_RES+\"alexnet loss (sin modificar classifier alexnet) SGD epochs=100 lr=3e-4 weight_decay=0.005 momentum=0.9.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "for e in resnet18.parameters():\n",
    "   e.requires_grad = False\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "resnet18.fc = nn.Linear(in_features=512, out_features=len(types), bias=True)\n",
    "optimizer = optim.SGD(resnet18.parameters(), lr=3e-4, weight_decay=0.005, momentum=0.9)\n",
    "resnet18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_resnet18, val_loss_resnet18 = train(resnet18, optimizer, loss_fn, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_resnet18, label=\"train loss\")\n",
    "plt.plot(val_loss_resnet18, label=\"val loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"num epochs\")\n",
    "plt.title(\"Loss vs num epochs\")\n",
    "plt.legend()\n",
    "# plt.show()\n",
    "plt.savefig(PATH_RES+\"resnet18 loss SGD epochs=100 lr=3e-4 weight_decay=0.005 momentum=0.9.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "test(resnet18, \"resnet18 confusion matrix SGD epochs=100 lr=3e-4 weight_decay=0.005 momentum=0.9.png\")"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "9899d9c7-2c90-4677-8138-4c8c81fa9231",
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "341268af697f69dd1ffdcdac7af840419ecb88f390bc16e46c3586102df69d04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
